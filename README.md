# Reddit Study Abroad Data Scraper

**Reddit ç•™å­¦æ•°æ®æŒ–æ˜ä¸å¤„ç†**

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„Redditçˆ¬è™«ç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºæŠ“å–å’Œåˆ†æç•™å­¦ç›¸å…³çš„è®¨è®ºæ•°æ®ã€‚é¡¹ç›®å®ç°äº†ä»æ•°æ®æŠ“å–åˆ°æ™ºèƒ½æ ‡ç­¾åŒ–çš„å®Œæ•´æµç¨‹ã€‚

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†æŠ€æœ¯æ–‡æ¡£ä¸­æè¿°çš„ä¸‰ä¸ªæ ¸å¿ƒéƒ¨åˆ†ï¼š

1. **Part 1: çˆ¬è™«æµç¨‹è®¾è®¡ä¸å®ç°** - ä»RedditæŠ“å–ç•™å­¦ç›¸å…³è®¨è®ºæ•°æ®
2. **Part 2: ç»“æ„åŒ–æ•°æ®å¤„ç†ç­–ç•¥** - æ•°æ®æ¸…æ´—ã€å»é‡å’Œç»“æ„åŒ–å¤„ç†
3. **Part 3: æ ‡ç­¾åŒ–ç­–ç•¥è®¾è®¡** - è‡ªåŠ¨åŒ–å†…å®¹åˆ†ç±»å’Œæƒ…æ„Ÿåˆ†æ

## åŠŸèƒ½ç‰¹æ€§

### ğŸ•·ï¸ Reddit APIçˆ¬è™«ç³»ç»Ÿ
- **Reddit API**: ç¨³å®šã€å¿«é€Ÿã€æ— IPé™åˆ¶çš„å®˜æ–¹APIæ¥å£
- æ”¯æŒå¤šä¸ªç•™å­¦ç›¸å…³å­ç‰ˆå— (r/ApplyingToCollege, r/gradadmissions, r/studyabroadç­‰)
- æ™ºèƒ½å»¶è¿Ÿå’Œé€Ÿç‡é™åˆ¶å¤„ç†
- è‡ªåŠ¨å»é‡å’Œå†…å®¹éªŒè¯
- ç»“æ„åŒ–æ•°æ®è·å–

### ğŸ§¹ æ•°æ®å¤„ç†å¼•æ“
- é«˜çº§æ–‡æœ¬æ¸…æ´—å’Œæ ‡å‡†åŒ–
- å®ä½“æå–ï¼šå¤§å­¦åç§°ã€ä¸“ä¸šã€é¡¹ç›®ç±»å‹
- æ™ºèƒ½å»é‡ï¼šåŸºäºå†…å®¹ç›¸ä¼¼åº¦çš„æ¨¡ç³Šå»é‡
- å¤šè¯­è¨€æ£€æµ‹å’Œè¿‡æ»¤
- å…³é”®å†…å®¹æå–å’Œæ‘˜è¦ç”Ÿæˆ

### ğŸ·ï¸ æ™ºèƒ½æ ‡ç­¾ç³»ç»Ÿ
- **ç”³è¯·éš¾åº¦åˆ†ç±»**ï¼šæéš¾/éš¾/ä¸­ç­‰/æ˜“
- **è¯¾ç¨‹è¯„ä»·åˆ†ç±»**ï¼šä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬/å·®
- **æƒ…æ„Ÿå€¾å‘åˆ†æ**ï¼šç§¯æ/æ¶ˆæ/ä¸­æ€§ (å«0-10è¯„åˆ†)
- åŸºäºå…³é”®è¯åŒ¹é…å’Œä¸Šä¸‹æ–‡åˆ†æ
- ç½®ä¿¡åº¦è¯„ä¼°å’Œé˜ˆå€¼è¿‡æ»¤

## å®‰è£…å’Œè®¾ç½®

### ç¯å¢ƒè¦æ±‚
- Python 3.8+
- SQLite3 (å†…ç½®) æˆ– MySQL 5.7+

### å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### Reddit APIè®¾ç½®
```bash
# 1. è¿è¡ŒAPIè®¾ç½®å‘å¯¼
python setup_reddit_api.py

# 2. æµ‹è¯•APIè¿æ¥
python main.py --test-api
```

### é…ç½®è®¾ç½®
ä¸»è¦é…ç½®é¡¹åœ¨ `config.yaml` æ–‡ä»¶ä¸­ï¼š

```yaml
# ç›®æ ‡å­ç‰ˆå—
subreddits:
  - "ApplyingToCollege"
  - "gradadmissions"
  - "studyabroad"

# Reddit APIè®¾ç½®
reddit_api:
  client_id: "your_client_id"
  client_secret: "your_client_secret"
  user_agent: "StudyAbroadScraper/1.0"

# çˆ¬è™«è®¾ç½®
scraping:
  max_posts_per_subreddit: 100
  max_comments_per_post: 50
```

## ä½¿ç”¨æ–¹æ³•

### å‘½ä»¤è¡Œç•Œé¢

```bash
# è¿è¡Œå®Œæ•´æµç¨‹ (æ¨è)
python main.py --full

# åªè¿è¡Œçˆ¬è™«
python main.py --scrape

# åªè¿è¡Œæ•°æ®å¤„ç†
python main.py --process

# åªè¿è¡Œæ ‡ç­¾åŒ–
python main.py --label

# æŸ¥çœ‹æ•°æ®ç»Ÿè®¡
python main.py --stats

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python main.py --config custom.yaml --full
```

### ç¼–ç¨‹æ¥å£

```python
from src.scraper import RedditScraper
from src.data_processor import DataProcessor
from src.labeling_system import LabelingSystem

# 1. æ•°æ®æŠ“å–
scraper = RedditScraper("config.yaml")
results = scraper.run_scraper()
scraper.close()

# 2. æ•°æ®å¤„ç†
processor = DataProcessor("config.yaml")
processor.process_all_posts()
processor.remove_invalid_data()

# 3. æ ‡ç­¾åŒ–
labeler = LabelingSystem("config.yaml")
labeler.label_all_posts()
stats = labeler.get_labeling_stats()
```

## æ•°æ®åº“ç»“æ„

é¡¹ç›®ä½¿ç”¨SQLiteæ•°æ®åº“å­˜å‚¨æ•°æ®ï¼Œä¸»è¦è¡¨ç»“æ„ï¼š

```sql
CREATE TABLE posts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    post_id TEXT UNIQUE,
    subreddit TEXT,
    question_title TEXT,
    answer_content_raw TEXT,
    answer_content_cleaned TEXT,
    university_name TEXT,
    major_name TEXT,
    program_name TEXT,
    key_content TEXT,
    content_hash TEXT,
    difficulty_label TEXT,
    course_evaluation_label TEXT,
    sentiment_label TEXT,
    sentiment_score REAL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processed_at TIMESTAMP
);
```

## æµ‹è¯•

è¿è¡Œå•å…ƒæµ‹è¯•ï¼š

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/ -v

# è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•
python -m pytest tests/test_scraper.py -v
python -m pytest tests/test_data_processor.py -v
python -m pytest tests/test_labeling_system.py -v

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
python -m pytest tests/ --cov=src --cov-report=html
```

## é¡¹ç›®ç»“æ„

```
reddit-scraper/
â”œâ”€â”€ src/                    # æºä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scraper.py         # çˆ¬è™«æ¨¡å—
â”‚   â”œâ”€â”€ data_processor.py  # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ labeling_system.py # æ ‡ç­¾ç³»ç»Ÿæ¨¡å—
â”‚   â””â”€â”€ utils.py           # å·¥å…·å‡½æ•°
â”œâ”€â”€ tests/                 # æµ‹è¯•æ–‡ä»¶
â”‚   â”œâ”€â”€ test_scraper.py
â”‚   â”œâ”€â”€ test_data_processor.py
â”‚   â””â”€â”€ test_labeling_system.py
â”œâ”€â”€ main.py               # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ config.yaml           # é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt      # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md            # é¡¹ç›®æ–‡æ¡£
```

## æŠ€æœ¯å®ç°äº®ç‚¹

### 1. åçˆ¬è™«ç­–ç•¥
- éšæœºUser-Agentè½®æ¢
- æ™ºèƒ½è¯·æ±‚å»¶è¿Ÿ (1-3ç§’éšæœº)
- å¼‚å¸¸å¤„ç†å’Œé‡è¯•æœºåˆ¶
- æ”¯æŒä»£ç†IPæ± æ‰©å±•

### 2. æ•°æ®è´¨é‡ä¿è¯
- å¤šå±‚æ¬¡æ–‡æœ¬æ¸…æ´—
- åŸºäºç›¸ä¼¼åº¦çš„æ™ºèƒ½å»é‡
- å®ä½“è¯†åˆ«å’Œæ ‡å‡†åŒ–
- å†…å®¹æœ‰æ•ˆæ€§éªŒè¯

### 3. æ™ºèƒ½æ ‡ç­¾ç³»ç»Ÿ
- å¤šç»´åº¦åˆ†ç±» (éš¾åº¦/è¯„ä»·/æƒ…æ„Ÿ)
- ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å…³é”®è¯åŒ¹é…
- ç½®ä¿¡åº¦è¯„ä¼°å’Œé˜ˆå€¼è¿‡æ»¤
- å¦å®šå¥å¤„ç†å’Œæƒ…æ„Ÿå¼ºåº¦åˆ†æ

## æ€§èƒ½å’Œæ‰©å±•æ€§

- **å¤„ç†èƒ½åŠ›**ï¼šæ”¯æŒæ•°åƒæ¡å¸–å­çš„æ‰¹é‡å¤„ç†
- **å­˜å‚¨æ•ˆç‡**ï¼šSQLiteæ•°æ®åº“ï¼Œæ”¯æŒç´¢å¼•ä¼˜åŒ–
- **æ¨¡å—åŒ–è®¾è®¡**ï¼šå„ç»„ä»¶ç‹¬ç«‹ï¼Œæ˜“äºæ‰©å±•
- **é…ç½®é©±åŠ¨**ï¼šé€šè¿‡YAMLæ–‡ä»¶çµæ´»é…ç½®

## æ³¨æ„äº‹é¡¹

1. **åˆè§„ä½¿ç”¨**ï¼šè¯·éµå®ˆRedditçš„ä½¿ç”¨æ¡æ¬¾å’Œrobots.txt
2. **é€Ÿç‡é™åˆ¶**ï¼šå»ºè®®è®¾ç½®åˆç†çš„è¯·æ±‚å»¶è¿Ÿï¼Œé¿å…IPè¢«å°
3. **æ•°æ®å¤‡ä»½**ï¼šé‡è¦æ•°æ®è¯·åŠæ—¶å¤‡ä»½
4. **ç½‘ç»œç¯å¢ƒ**ï¼šæŸäº›åœ°åŒºå¯èƒ½éœ€è¦ä»£ç†è®¿é—®Reddit

## æœªæ¥æ”¹è¿›æ–¹å‘

1. **æ·±åº¦å­¦ä¹ é›†æˆ**ï¼šä½¿ç”¨BERT/GPTç­‰æ¨¡å‹æå‡æ ‡ç­¾å‡†ç¡®æ€§
2. **å®æ—¶ç›‘æ§**ï¼šæ·»åŠ æ•°æ®è´¨é‡ç›‘æ§å’Œå¼‚å¸¸å‘Šè­¦
3. **å¯è§†åŒ–ç•Œé¢**ï¼šå¼€å‘Webç•Œé¢ç”¨äºæ•°æ®æŸ¥çœ‹å’Œç®¡ç†
4. **åˆ†å¸ƒå¼å¤„ç†**ï¼šæ”¯æŒå¤šè¿›ç¨‹/å¤šæœºå™¨å¹¶è¡Œå¤„ç†
5. **APIæ¥å£**ï¼šæä¾›RESTful APIä¾›å…¶ä»–ç³»ç»Ÿè°ƒç”¨

